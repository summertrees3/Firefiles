
python动态语言
-----1-----
list[]：有序可重复集合，可以随时添加和删除其中的元素；len/append/insert/pop/
tuple()：不能修改
set{}：无序无重复，元素是不可变对象；add/remove
dict{}：key必须是不可变对象；get/pop
-----2-----
函数可以同时返回多个值，其实就是一个tuple。
-----3-----
生成器()：边循环边计算；(x * x for x in range(10))
-----4-----
__name，类的private私有变量，使用get_name，set_name
__xxx__是特殊变量，特殊变量是可以直接访问的
-----5-----
实例属性优先级比类属性高
给一个实例绑定的方法，对另一个实例是不起作用的
__slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称
-----6-----
@property广泛应用在类的定义中，可以保证对参数进行必要的检查
-----7-----
在一个python进程中，GIL(全局解释器锁)只有一个，导致了多线程无法利用多核





数据分析补充：
arr.astype(np.float64)：	转换dtype
data[~(names == 'Bob')]：	~操作符用来反转条件
np.where(arr > 0, 2, arr):	将所有正值替换为2，所有负值不变
axis：0沿行方向↓，1沿列方向→
x.dot(y)：矩阵点积
np.random.seed(1234)：更改随机数生成种子
pd.isnull()	notnull()
inplace=True：小心使用，它会销毁所有被删除的数据；对现有对象进行就地修改，不返回新对象
利用标签的切片loc运算与普通的Python切片运算不同，其末端是包含的（含头含尾）
df1.add(df2, fill_value=0)：填充值fill_value
frame.sort_index(axis=1, ascending=False)：按轴上索引降序排序
frame.sort_values(by=['a', 'b'])：按值排序
corr方法用于计算两个Series中重叠的、非NA的、按索引对齐的值的相关系数。cov用于计算协方差。
value_counts用于计算一个Series中各值出现的频率，按值频率降序排列
close_timestamps=pd.to_datetime(failures['Closing Date']) close_timestamps.dt.year.value_counts()	计算按年份倒闭的银行数



pd.read_csv('examples/ex2.csv', )	
header=None	文件第一行非列名，自动添加arange
names=['a', 'b', 'c', 'd', 'message']	自定义列名
index_col=['key1', 'key2']	将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表
skiprows=[0, 2, 3]	跳过文件的第一、三、四行

pd.read_table('examples/ex3.txt', sep='\s+')	sep分隔符：字段是被数量不同的空白字符间隔开

data.to_csv('examples/out.csv', )
sep='|'	分隔符
na_rep='NULL'	缺失值在输出结果中会被表示为空字符串，用NULL替代
index=False, header=False	禁用行和列的标签
columns=['a', 'b', 'c']	只写出一部分的列
encoding="utf_8_sig"	中文乱码



丢弃缺失数据：
 dropna(axis=1, how='all'/'any')
填充缺失数据：
 fillna(0)
 fillna({1: 0.5, 2: 0})	对不同的列填充不同的值
 fillna(method='ffill', limit=2)	用前一个非缺失值去填充该缺失值，反之bfill
移除重复数据：
 drop_duplicates(['k1', 'k2'], keep='last')
利用函数或映射进行数据转换：
 lowercased.map(meat_to_animal) 或 data['food'].map(lambda x: meat_to_animal[x.lower()])	Series的map方法可以接受一个函数或含有映射关系的字典型对象
替换值：
 data.replace([-999, -1000], [np.nan, 0])
 data.replace({-999: np.nan, -1000: 0})
结合字典型对象实现对部分轴标签的更新：
 data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'})
面元划分：
 pd.cut(ages, bins, labels=group_names)
根据数据的值是正还是负，np.sign(data)可以生成1和-1



df.join(pd.get_dummies(df.color))
pd.merge(df1, df2, on=['key1', 'key2'], how='outer')	合并数据集(多对多连接产生的是行的笛卡尔积)
left2.join([right2, another], how='outer')		按【索引】合并，要求没有重叠的列		


df.groupby(['key1', 'key2']).size()
对分组进行迭代：
 for (k1, k2), group in df.groupby(['key1', 'key2']):
	print((k1, k2))
	print(group)
对部分列进行聚合：
 df.groupby(['key1', 'key2'])[['data2']].mean()
 df.groupby(['key1', 'key2'])['data2'].mean()
 返回的对象是一个已分组的DataFrame（如果传入的是列表或数组）或已分组的Series（如果传入的是标量形式的单个列名）
通过字典或Series分组：
 people.groupby(map_series, axis=1).count()
通过函数跟数组、列表、字典、Series混用分组：
 people.groupby([len, key_list]).min()
通过索引级别分组：
 hier_df.groupby(level='cty', axis=1).count()
 
对某几列应用一组聚合函数（重命名）：
 grouped['tip_pct', 'total_bill'].agg([('foo', 'mean'), ('bar', 'std')])
对不同的列应用不同的函数：
 grouped.agg({'tip_pct':['min', 'max', 'mean', 'std'], 'size':'sum'})
apply传入自定义函数：
 f = lambda x: x.describe()
 grouped.apply(f)

透视表pivot_table的aggfunc默认聚合类型：分组平均数mean
只聚合tip_pct和size，而且想根据time和day进行分组，将smoker放到列上：
 tips.pivot_table(['tip_pct', 'size'],  index=['time', 'day'], columns='smoker')
 tips.groupby(['time', 'day', 'smoker'])[['tip_pct', 'size']].mean().unstack()	——使用groupby实现
交叉表crosstab计算分组频率：
 pd.crosstab([tips.time, tips.day], tips.smoker, margins=True)
 tips.pivot_table('size', index=['time','day'], columns='smoker', aggfunc='count',  margins=True, fill_value=0)		——使用pivot_table实现



时间：
parse('Jan 31, 1997 10:45 PM')	解析日期
pd.to_datetime(datestrs)	处理成组日期
pd.date_range('1/1/2000', periods=1000, freq='W-WED')	
 start/end			开始/结束日期
 normalize=True		规范化到午夜的时间戳
ts.shift(2)				位移数据，索引不变
ts.shift(2, freq='M')	对时间戳位移，数据不变
ts.resample('M').mean()
tz_localize/tz_convert	时区本地化/转换
pd.period_range('2000-01-01', '2000-06-30', freq='M')	时期范围
p = pd.Period('2007', freq='A-DEC')
 p.asfreq('M', how='start')		频率转换
pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC')		将年和季度合并成一个索引
ts.resample('M', kind='period').mean()	降采样后聚合
ts.resample('5min').ohlc()		计算各面元的四个值:open/high/low/close




画图：
fig=plt.figure();ax=fig.add_subplot(1,1,1)
fig,axes=plt.subplots(2,1)
plot	线型图
plot.bar、barh	柱状图		减少绘图前合计数据的工作量：seaborn.barplot(x='tip_pct', y='day', hue='time', data=tips, orient='h')
plot.hist(bins=50)	直方图
plot.density/kde	密度图		同时实现直方图+密度图：seaborn.distplot(values, bins=100, color='k')
seaborn.regplot('m1', 'unemp', data=trans_data)		散布图/点图
seaborn.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2})	散布图矩阵：支持在对角线上放置每个变量的直方图或密度估计，plot_kws参数可以让我们传递配置选项到非对角线元素上的图形使用
seaborn.factorplot(x='day', y='tip_pct', hue='time', col='smoker', kind='bar', data=tips[tips.tip_pct < 1])	分面网格		盒图：kind='box'





relplot
lmplot
catplot
boxplot
scatterplot
jointplot
pairplot

用散点图关联变量
用线图强调连续性





【总结】
带标签的训练集——回归、分类
参数化模型：线性回归、对数几率回归、支持向量机
非参数模型：KNN最近邻、决策树、随机森林

无标签的训练集——聚类、降维
k均值聚类、层次聚类
主成分分析（PCA）、奇异值分解（SVD）



【总结】
1、深度学习和强化学习首先都是自主学习系统。它们之间的区别在于，深度学习是从训练集中学习（使用现有数据来训练算法），然后将学习到的知识应用于新数据集，是一种静态学习；而强化学习是通过连续的反馈（实践）来调整自身的动作以获得最优结果，是一种不断试错的过程，它是动态学习。
2、CNN对于图像、计算机视觉任务非常高效，RNN拥有内建记忆适合语言问题。



训练集、验证集和测试集；训练集用来模型训练，验证集用来调整参数，而测试集用来衡量模型表现好坏。



【02-25总结】
python  -m pip install --upgrade pip
pip install --upgrade --ignore-installed tensorflow
anaconda安装tensorflow时加入的numpy，
需要在安装完成后pip uninstall numpy==1.16.1掉

回归：预测数量，定量输出，连续变量预测
分类：预测标签，定性输出，离散变量预测


【02-26总结】
AI>>机器学习>>神经网络

人工智能中的六大主要算法和技术：
1.机器学习 2.搜索和优化算法 3.约束满足
4.逻辑推理 5.概率推理 6.控制理论



一致为真，预测判阴阳。
TP真阳性：预测为正，实际也为正
FP假阳性：预测为正，实际为负
FN假阴性：预测与负、实际为正
TN真阴性：预测为负、实际也为负。

精确率Precision：分母是预测为正的样本数
召回率Recall：分母是原来样本中所有的正样本数
精确率P = TP真阳性/(TP真阳性+FP假阳性)
召回率R = TP真阳性/(TP真阳性+FN假阴性)

F1分数（F1Score）可以看作是模型精确率和召回率的一种加权平均，它的最大值是1，最小值是0，越大越好，1为理想状态。
F1 = 2*P*R/(P+R)

ROC曲线只需要真阳性率(TPR)和假阳性率(FPR)，将FPR和TPR定义为x和y轴，TPR就可以定义为灵敏度,而FPR就定义为1-特异度
AUC的含义：ROC曲线下的面积（越大越好，1为理想状态）


避免过拟合：
1.使用更多训练数据。
2.使用正则化，在损失函数里添加一个惩罚，来构建一个模型，避免为任意一个特征分配过多的解释性权重，或者允许考虑过多特征。



——————————————————————————————————————————————
*回归：线性回归是参数化方法


如果变量是连续的（例如房价），取它们的均值；如果变量是离散的（例如猫或者狗），取它们的众数。



2-Python学习（廖雪峰）---done
3-python数据分析二刷
4-视频课程：基础数学知识、机器学习（先看网易吴恩达）




Maths 数学:
1) Linear Algebra 线性代数
2) Calculus  微积分
3) Statistics 统计学
4) Probability 概率论



机器学习（模型层次结构角度）
浅层学习（Shallow Learning）：没有隐藏层或只有一层隐藏层，分类、回归、聚类、降维等
深度学习（Deep Learning）	：有较多的隐藏层
卷积神经网络(CNN)：计算机视觉、图像分类
递归神经网络(RNN)：LSTM和GRU，语言、文字



矩阵A:m×n，矩阵B:x×y，A×B的可行条件:n=x，结果矩阵C:m×y。
C=A×B的第1行第1列的元素由A的第1行元素与B的第1列元素对应相乘，再取乘积之和．


