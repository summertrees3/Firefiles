
python动态语言
-----1-----
list[]：有序可重复集合，可以随时添加和删除其中的元素；len/append/insert/pop/
tuple()：不能修改
set{}：无序无重复，元素是不可变对象；add/remove
dict{}：key必须是不可变对象；get/pop
-----2-----
函数可以同时返回多个值，其实就是一个tuple。
-----3-----
生成器()：边循环边计算；(x * x for x in range(10))
-----4-----
__name，类的private私有变量，使用get_name，set_name
__xxx__是特殊变量，特殊变量是可以直接访问的
-----5-----
实例属性优先级比类属性高
给一个实例绑定的方法，对另一个实例是不起作用的
__slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称
-----6-----
@property广泛应用在类的定义中，可以保证对参数进行必要的检查
-----7-----
在一个python进程中，GIL(全局解释器锁)只有一个，导致了多线程无法利用多核





数据分析补充：
arr.astype(np.float64)：	转换dtype
data[~(names == 'Bob')]：	~操作符用来反转条件
np.where(arr > 0, 2, arr):	将所有正值替换为2，所有负值不变
axis：0沿行方向↓，1沿列方向→
x.dot(y)：矩阵点积
np.random.seed(1234)：更改随机数生成种子
pd.isnull()	notnull()
inplace=True：小心使用，它会销毁所有被删除的数据；对现有对象进行就地修改，不返回新对象
利用标签的切片loc运算与普通的Python切片运算不同，其末端是包含的（含头含尾）
df1.add(df2, fill_value=0)：填充值fill_value
frame.sort_index(axis=1, ascending=False)：按轴上索引降序排序
frame.sort_values(by=['a', 'b'])：按值排序
corr方法用于计算两个Series中重叠的、非NA的、按索引对齐的值的相关系数。cov用于计算协方差。
value_counts用于计算一个Series中各值出现的频率，按值频率降序排列
close_timestamps=pd.to_datetime(failures['Closing Date']) close_timestamps.dt.year.value_counts()	计算按年份倒闭的银行数



pd.read_csv('examples/ex2.csv', )	
header=None	文件第一行非列名，自动添加arange
names=['a', 'b', 'c', 'd', 'message']	自定义列名
index_col=['key1', 'key2']	将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表
skiprows=[0, 2, 3]	跳过文件的第一、三、四行

pd.read_table('examples/ex3.txt', sep='\s+')	sep分隔符：字段是被数量不同的空白字符间隔开

data.to_csv('examples/out.csv', )
sep='|'	分隔符
na_rep='NULL'	缺失值在输出结果中会被表示为空字符串，用NULL替代
index=False, header=False	禁用行和列的标签
columns=['a', 'b', 'c']	只写出一部分的列
encoding="utf_8_sig"	中文乱码



丢弃缺失数据：
 dropna(axis=1, how='all'/'any')
填充缺失数据：
 fillna(0)
 fillna({1: 0.5, 2: 0})	对不同的列填充不同的值
 fillna(method='ffill', limit=2)	用前一个非缺失值去填充该缺失值，反之bfill
移除重复数据：
 drop_duplicates(['k1', 'k2'], keep='last')
利用函数或映射进行数据转换：
 lowercased.map(meat_to_animal) 或 data['food'].map(lambda x: meat_to_animal[x.lower()])	Series的map方法可以接受一个函数或含有映射关系的字典型对象
替换值：
 data.replace([-999, -1000], [np.nan, 0])
 data.replace({-999: np.nan, -1000: 0})
结合字典型对象实现对部分轴标签的更新：
 data.rename(index={'OHIO': 'INDIANA'}, columns={'three': 'peekaboo'})
面元划分：
 pd.cut(ages, bins, labels=group_names)
根据数据的值是正还是负，np.sign(data)可以生成1和-1



df.join(pd.get_dummies(df.color))
pd.merge(df1, df2, on=['key1', 'key2'], how='outer')	合并数据集(多对多连接产生的是行的笛卡尔积)
left2.join([right2, another], how='outer')		按【索引】合并，要求没有重叠的列		


df.groupby(['key1', 'key2']).size()
对分组进行迭代：
 for (k1, k2), group in df.groupby(['key1', 'key2']):
	print((k1, k2))
	print(group)
对部分列进行聚合：
 df.groupby(['key1', 'key2'])[['data2']].mean()
 df.groupby(['key1', 'key2'])['data2'].mean()
 返回的对象是一个已分组的DataFrame（如果传入的是列表或数组）或已分组的Series（如果传入的是标量形式的单个列名）
通过字典或Series分组：
 people.groupby(map_series, axis=1).count()
通过函数跟数组、列表、字典、Series混用分组：
 people.groupby([len, key_list]).min()
通过索引级别分组：
 hier_df.groupby(level='cty', axis=1).count()
 
对某几列应用一组聚合函数（重命名）：
 grouped['tip_pct', 'total_bill'].agg([('foo', 'mean'), ('bar', 'std')])
对不同的列应用不同的函数：
 grouped.agg({'tip_pct':['min', 'max', 'mean', 'std'], 'size':'sum'})
apply传入自定义函数：
 f = lambda x: x.describe()
 grouped.apply(f)

透视表pivot_table的aggfunc默认聚合类型：分组平均数mean
只聚合tip_pct和size，而且想根据time和day进行分组，将smoker放到列上：
 tips.pivot_table(['tip_pct', 'size'],  index=['time', 'day'], columns='smoker')
 tips.groupby(['time', 'day', 'smoker'])[['tip_pct', 'size']].mean().unstack()	——使用groupby实现
交叉表crosstab计算分组频率：
 pd.crosstab([tips.time, tips.day], tips.smoker, margins=True)
 tips.pivot_table('size', index=['time','day'], columns='smoker', aggfunc='count',  margins=True, fill_value=0)		——使用pivot_table实现



时间：
parse('Jan 31, 1997 10:45 PM')	解析日期
pd.to_datetime(datestrs)	处理成组日期
pd.date_range('1/1/2000', periods=1000, freq='W-WED')	
 start/end			开始/结束日期
 normalize=True		规范化到午夜的时间戳
ts.shift(2)				位移数据，索引不变
ts.shift(2, freq='M')	对时间戳位移，数据不变
ts.resample('M').mean()
tz_localize/tz_convert	时区本地化/转换
pd.period_range('2000-01-01', '2000-06-30', freq='M')	时期范围
p = pd.Period('2007', freq='A-DEC')
 p.asfreq('M', how='start')		频率转换
pd.PeriodIndex(year=data.year, quarter=data.quarter, freq='Q-DEC')		将年和季度合并成一个索引
ts.resample('M', kind='period').mean()	降采样后聚合
ts.resample('5min').ohlc()		计算各面元的四个值:open/high/low/close




画图：
fig=plt.figure();ax=fig.add_subplot(1,1,1)
fig,axes=plt.subplots(2,1)
plot	线型图
plot.bar、barh	柱状图		减少绘图前合计数据的工作量：seaborn.barplot(x='tip_pct', y='day', hue='time', data=tips, orient='h')
plot.hist(bins=50)	直方图
plot.density/kde	密度图		同时实现直方图+密度图：seaborn.distplot(values, bins=100, color='k')
seaborn.regplot('m1', 'unemp', data=trans_data)		散布图/点图
seaborn.pairplot(trans_data, diag_kind='kde', plot_kws={'alpha': 0.2})	散布图矩阵：支持在对角线上放置每个变量的直方图或密度估计，plot_kws参数可以让我们传递配置选项到非对角线元素上的图形使用
seaborn.factorplot(x='day', y='tip_pct', hue='time', col='smoker', kind='bar', data=tips[tips.tip_pct < 1])	分面网格		盒图：kind='box'





relplot
lmplot
catplot
boxplot
scatterplot
jointplot
pairplot

用散点图关联变量
用线图强调连续性



水和酒精是主要成分，有机物包括：高级醇、甲醇、多元醇、醛类、羧酸、酯类、酸类等
乙酸和乳酸是白酒中含量最大的两种酸
酯类主要包括乙酸乙酯、丁酸乙酯、醋酸戊酯、丁酸戊酯、乳酸乙酯等
醛类包括甲醛、乙醛、糠醛、丁醛和戊醛等
异戊醇、丁醇、异丁醇、丙醇、异丙醇和少量环状醇。其中以异戊醇、异丁醇较多。

酒是发酵产物，其中有甲酸、乙酸、丁酸、乙酸乙酯、丁酸乙酯、乙酸戎酯、丁酸戎酯，少量的丙醇、丁醇、戎醇等。

现有结论：
入池酸度与总酯正相关



【总结】
带标签的训练集——回归、分类
参数化模型：线性回归、对数几率回归、支持向量机
非参数模型：KNN最近邻、决策树、随机森林

无标签的训练集——聚类、降维
k均值聚类、层次聚类
主成分分析（PCA）、奇异值分解（SVD）



【总结】
1、深度学习和强化学习首先都是自主学习系统。它们之间的区别在于，深度学习是从训练集中学习（使用现有数据来训练算法），然后将学习到的知识应用于新数据集，是一种静态学习；而强化学习是通过连续的反馈（实践）来调整自身的动作以获得最优结果，是一种不断试错的过程，它是动态学习。
2、CNN对于图像、计算机视觉任务非常高效，RNN拥有内建记忆适合语言问题。



洋河酒厂数据平台：http://47.97.107.175/YHBD/#/home
admin
nzbscklj



【6-6 工作】
1、【原酒理化数据】中的排次改为出池排次，值改为1排、2排、3排、4排；组编号1-20改为01组-20组，复制相同列，其中一列1B-20B改为01组-20组。
2、已合并【原酒理化数据】和【stepA_1】，将根据下方结论进行筛选。

酒厂结论：
--【原酒理化数据】取样日期 减去【stepA_1】出池日期，大于等于4小于等于10。



【总结】


